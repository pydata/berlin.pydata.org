<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Beyond the Black Box: Interpreting ML models with SHAP - PyData Berlin 2025</title>
<meta name="description" content="As machine learning models become more accurate and complex, explainability remains essential. Explainability helps not just with trust and transparency but als... By Avik Basu">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://berlin.pydata.org/conferences/2025/SB88M7.html">
<meta property="og:title" content="Beyond the Black Box: Interpreting ML models with SHAP - PyData Berlin 2025">
<meta property="og:description" content="As machine learning models become more accurate and complex, explainability remains essential. Explainability helps not just with trust and transparency but als... By Avik Basu">
<meta property="og:image" content="https://berlin.pydata.org/images/social/SB88M7.png">
<meta property="og:site_name" content="PyData Berlin">

<!-- Twitter Card -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:url" content="https://berlin.pydata.org/conferences/2025/SB88M7.html">
<meta name="twitter:title" content="Beyond the Black Box: Interpreting ML models with SHAP - PyData Berlin 2025">
<meta name="twitter:description" content="As machine learning models become more accurate and complex, explainability remains essential. Explainability helps not just with trust and transparency but als... By Avik Basu">
<meta name="twitter:image" content="https://berlin.pydata.org/images/social/SB88M7.png">
<meta name="twitter:site" content="@pydataberlin">

<!-- Canonical URL -->
<link rel="canonical" href="https://berlin.pydata.org/conferences/2025/SB88M7.html">

<link rel="stylesheet" href="../../css/main.css" />
<!--[if lte IE 8]><link rel="stylesheet" href="../../css/ie8.css" /><![endif]-->
<!--[if lte IE 9]><link rel="stylesheet" href="../../css/ie9.css" /><![endif]-->
<style>
    .session-header {
        background: linear-gradient(to bottom, rgba(46, 49, 65, 0.8), rgba(46, 49, 65, 0.8)), url(../../images/banner.jpg);
        background-size: cover;
        background-position: center;
        padding: 4em 0 2em 0;
        text-align: center;
        color: white;
    }
    .session-info {
        background: #f5f5f5;
        padding: 1em 2em;
        margin-bottom: 2em;
        border-radius: 4px;
    }
    .session-info span {
        display: inline-block;
        margin-right: 2em;
        font-weight: 600;
    }
    .speaker-card {
        background: #f9f9f9;
        padding: 2em;
        margin-bottom: 2em;
        border-radius: 4px;
        display: flex;
        gap: 2em;
    }
    .speaker-image {
        width: 150px;
        height: 150px;
        object-fit: cover;
        border-radius: 50%;
        flex-shrink: 0;
    }
    .speaker-info {
        flex-grow: 1;
    }
    .social-links {
        margin-top: 1em;
    }
    .social-links a {
        margin-right: 1em;
        color: #4a4e69;
    }
    .track-badge {
        display: inline-block;
        background: #4a4e69;
        color: white;
        padding: 0.3em 1em;
        border-radius: 20px;
        font-size: 0.9em;
        margin-bottom: 1em;
    }
    .content-section {
        max-width: 900px;
        margin: 0 auto;
        padding: 2em;
    }
    .session-image-section {
        background: #fff;
        padding: 2em 0;
    }
    .session-image {
        display: block;
        max-width: 100%;
        height: auto;
        margin: 0 auto;
        border-radius: 8px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    @media screen and (max-width: 736px) {
        .speaker-card {
            flex-direction: column;
            text-align: center;
        }
        .speaker-image {
            margin: 0 auto;
        }
        .session-image-section {
            padding: 1em 0;
        }
    }
</style>
</head>
<body>

<div id="page-wrapper">

<header id="header">
<h1><a href="../../index.html">PyData Berlin</a></h1>
<nav id="nav">
<ul>
<li class="special">
<a href="#menu" class="menuToggle"><span>Menu</span></a>
<div id="menu">
<ul>
<li><a href="../../index.html">Home</a></li>
<li><a href="../../code-of-conduct/en">Code of Conduct</a></li>
<li><a href="https://pydata.org/berlin2025/">PyData Berlin 2025</a></li>
<li><a href="../../blog/">Posts</a></li>
</ul>
</div>
</li>
</ul>
</nav>
</header>

<section class="session-header">
    <div class="inner">
        
        <span class="track-badge">Visualisation & Jupyter</span>
        
        <h1>Beyond the Black Box: Interpreting ML models with SHAP</h1>
        <p style="font-size: 1.2em; margin-top: 1em;">Talk</p>
    </div>
</section>


<section class="session-image-section">
    <div class="content-section">
        <img src="https://berlin.pydata.org/images/social/SB88M7.png" alt="Beyond the Black Box: Interpreting ML models with SHAP - Session Card" class="session-image">
    </div>
</section>


<section class="wrapper style5">
    <div class="content-section">
        
        <div class="session-info">
            <span><strong>Level:</strong> Novice</span>
            
            <span><strong>Company/Institute:</strong> Intuit</span>
            
            
            
        </div>

        <h2>Abstract</h2>
        <p>As machine learning models become more accurate and complex, explainability remains essential. Explainability helps not just with trust and transparency but also with generating actionable insights and guiding decision-making. One way of interpreting the model outputs is using SHapley Additive exPlanations (SHAP). In this talk, I will go through the concept of Shapley values and its mathematical intuition and then walk through a few real-world examples for different ML models. Attendees will gain a practical understanding of SHAP's strengths and limitations and how to use it to explain model predictions in their projects effectively.</p>

        
        <h3>Prerequisites</h3>
        <p>Basic understanding of
- Tree based models
- Neural Networks</p>
        

        <h2>Description</h2>
        <div class="description-content">
            <h2>Audience</h2>
<p>This talk is for Data Scientists and Machine Learning Engineers at any level. Basic knowledge of machine learning is useful but not necessary.</p>
<h2>Objective</h2>
<p>Attendees will learn why explainable machine learning is important and how to use and interpret SHAP values for their model.</p>
<h2>Details</h2>
<p>ML models behave as black boxes in most scenarios. The model predicts or provides a certain output, but it is very difficult to generate any actionable insights directly. This is mostly because we generally have no idea which features are contributing the most to the model's behavior internally. SHAP provides a way to explain model predictions and can be an important tool in a data scientist's toolbox.</p>
<p>In this talk, we will begin by explaining to the audience the need for explainability and why it is essential to understand beyond what the model outputs. We will then briefly review the mathematical intuition behind Shapley values and their origins in game theory. After that, we will walk through a couple of case studies of tree-based and neural network-based models. We will be focusing on the interpretation of SHAP through various plots. Finally, we will discuss the best practices for interpreting SHAP visualizations, handling large datasets, and common pitfalls to avoid.</p>
<h2>Outline</h2>
<ul>
<li>Introduction and motivation [1 min]</li>
<li>Why explainability matters? [5 min]</li>
<li>Problem with black box models</li>
<li>Actionable insights</li>
<li>SHAP theory and intuition [5 min]<ul>
<li>Shapley values</li>
<li>Game theory origins</li>
<li>SHAP</li>
</ul>
</li>
<li>Case study 1: Tree-based model [4 min]<ul>
<li>Problem definition</li>
<li>model output</li>
<li>SHAP visualization</li>
<li>Global plots</li>
<li>Local plots</li>
<li>Interpretation</li>
</ul>
</li>
<li>Case study 2: Neural Network model [8 min]<ul>
<li>Problem definition</li>
<li>Model output</li>
<li>SHAP visualization</li>
<li>Global plots</li>
<li>Local plots</li>
<li>Interpretation</li>
</ul>
</li>
<li>Best practices and common pitfalls [4 min]<ul>
<li>Interpret SHAP correctly</li>
<li>Avoid misleading explanations</li>
<li>Performance challenges for large datasets</li>
<li>Other techniques for explainability</li>
</ul>
</li>
<li>Q/A [3 min]</li>
</ul>
        </div>

        <h2>Speaker</h2>
        
        <div class="speaker-card">
            
            <img src="https://cfp.pydata.org/media/avatars/SF109285-Edit-Web_YQaphsB.jpg" alt="Avik Basu" class="speaker-image">
            
            <div class="speaker-info">
                <h3>Avik Basu</h3>
                
                <p><strong>Staff Data Scientist</strong></p>
                
                
                <p>Avik Basu is a Staff Data Scientist passionate about building intelligent, scalable systems that blend research with practical impact. With extensive experience in time series modeling, anomaly detection, and explainable AI, he focuses on making machine learning robust, interpretable, and production-ready.

Avik is a frequent speaker at conferences like PyCascades, PyData and KubeCon, where he shares insights on topics such as reproducible ML workflows, ML-driven observability, etc. He is also an active contributor to the open-source ecosystem, serving as a maintainer of the real-time data processing framework Numaflow and a reviewer for scientific Python projects.

Outside of work, he explores the intersection of machine learning, personal finance, and open-source tools, aiming to build software that is accessible, self-hostable, and privacy-focused. He is driven by a strong belief in community, transparency, and empowering others through education and mentorship.</p>
                
                
            </div>
        </div>
        

        <div style="text-align: center; margin-top: 3em;">
            <a href="https://pydata.org/berlin2025/" class="button special">View Full Conference Program</a>
        </div>

    </div>
</section>

<footer id="footer">
    <ul class="icons">
        <li><a href="https://twitter.com/pydataberlin" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
        <li><a href="https://github.com/pydataberlin" class="icon fa-github"><span class="label">Github</span></a></li>
    </ul>
    <ul class="copyright">
        <li>&copy; PyData Berlin</li>
        <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
    </ul>
</footer>

</div>

<script src="../../js/jquery.min.js"></script>
<script src="../../js/jquery.scrollex.min.js"></script>
<script src="../../js/jquery.scrolly.min.js"></script>
<script src="../../js/skel.min.js"></script>
<script src="../../js/util.js"></script>
<script src="../../js/main.js"></script>

</body>
</html>